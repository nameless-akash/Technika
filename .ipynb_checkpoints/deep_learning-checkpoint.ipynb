{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d10fdf",
   "metadata": {
    "papermill": {
     "duration": 0.006244,
     "end_time": "2022-05-05T17:51:42.959708",
     "exception": false,
     "start_time": "2022-05-05T17:51:42.953464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Welcome to Deep Learning! #\n",
    "\n",
    "Welcome to Kaggle's *Introduction to Deep Learning* course! You're about to learn all you need to get started building your own deep neural networks. Using Keras and Tensorflow you'll learn how to:\n",
    "- create a **fully-connected** neural network architecture\n",
    "- apply neural nets to two classic ML problems: **regression** and **classification**\n",
    "- train neural nets with **stochastic gradient descent**, and\n",
    "- improve performance with **dropout**, **batch normalization**, and other techniques\n",
    "\n",
    "The tutorials will introduce you to these topics with fully-worked examples, and then in the exercises, you'll explore these topics in more depth and apply them to real-world datasets.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "# What is Deep Learning? #\n",
    "\n",
    "Some of the most impressive advances in artificial intelligence in recent years have been in the field of *deep learning*. Natural language translation, image recognition, and game playing are all tasks where deep learning models have neared or even exceeded human-level performance.\n",
    "\n",
    "So what is deep learning? **Deep learning** is an approach to machine learning characterized by deep stacks of computations. This depth of computation is what has enabled deep learning models to disentangle the kinds of complex and hierarchical patterns found in the most challenging real-world datasets.\n",
    "\n",
    "Through their power and scalability **neural networks** have become the defining model of deep learning.  Neural networks are composed of neurons, where each neuron individually performs only a simple computation. The power of a neural network comes instead from the complexity of the connections these neurons can form.\n",
    "\n",
    "# The Linear Unit #\n",
    "\n",
    "So let's begin with the fundamental component of a neural network: the individual neuron. As a diagram, a **neuron** (or **unit**) with one input looks like:\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/mfOlDR6.png\" width=\"250\" alt=\"Diagram of a linear unit.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>The Linear Unit: $y = w x + b$\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "The input is `x`. Its connection to the neuron has a **weight** which is `w`. Whenever a value flows through a connection, you multiply the value by the connection's weight. For the input `x`, what reaches the neuron is `w * x`. A neural network \"learns\" by modifying its weights.\n",
    "\n",
    "The `b` is a special kind of weight we call the **bias**. The bias doesn't have any input data associated with it; instead, we put a `1` in the diagram so that the value that reaches the neuron is just `b` (since `1 * b = b`). The bias enables the neuron to modify the output independently of its inputs.\n",
    "\n",
    "The `y` is the value the neuron ultimately outputs. To get the output, the neuron sums up all the values it receives through its connections. This neuron's activation is `y = w * x + b`, or as a formula $y = w x + b$.\n",
    "\n",
    "<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #ebf9ff; padding: 1em; margin:24px;\">\n",
    "    <strong>Does the formula $y=w x + b$ look familiar?</strong><br>\n",
    "It's an equation of a line! It's the slope-intercept equation, where $w$ is the slope and $b$ is the y-intercept. \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace11730",
   "metadata": {
    "papermill": {
     "duration": 0.004767,
     "end_time": "2022-05-05T17:51:42.969669",
     "exception": false,
     "start_time": "2022-05-05T17:51:42.964902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Example - The Linear Unit as a Model #\n",
    "\n",
    "Though individual neurons will usually only function as part of a larger network, it's often useful to start with a single neuron model as a baseline. Single neuron models are *linear* models. \n",
    "\n",
    "Let's think about how this might work on a dataset like [80 Cereals](https://www.kaggle.com/crawford/80-cereals). Training a model with `'sugars'` (grams of sugars per serving) as input and `'calories'` (calories per serving) as output, we might find the bias is `b=90` and the weight is `w=2.5`. We could estimate the calorie content of a cereal with 5 grams of sugar per serving like this:\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/yjsfFvY.png\" width=\"1000\" alt=\"Computing with the linear unit.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>Computing with the linear unit.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "And, checking against our formula, we have $calories = 2.5 \\times 5 + 90 = 102.5$, just like we expect.\n",
    "\n",
    "# Multiple Inputs #\n",
    "\n",
    "The *80 Cereals* dataset has many more features than just `'sugars'`. What if we wanted to expand our model to include things like fiber or protein content? That's easy enough. We can just add more input connections to the neuron, one for each additional feature. To find the output, we would multiply each input to its connection weight and then add them all together.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/vyXSnlZ.png\" width=\"300\" alt=\"Three input connections: x0, x1, and x2, along with the bias.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>A linear unit with three inputs.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "The formula for this neuron would be $y = w_0 x_0 + w_1 x_1 + w_2 x_2 + b$. A linear unit with two inputs will fit a plane, and a unit with more inputs than that will fit a hyperplane.\n",
    "\n",
    "# Linear Units in Keras #\n",
    "\n",
    "The easiest way to create a model in Keras is through `keras.Sequential`, which creates a neural network as a stack of *layers*. We can create models like those above using a *dense* layer (which we'll learn more about in the next lesson).\n",
    "\n",
    "We could define a linear model accepting three input features (`'sugars'`, `'fiber'`, and `'protein'`) and producing a single output (`'calories'`) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ffc8c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:42.981345Z",
     "iopub.status.busy": "2022-05-05T17:51:42.980950Z",
     "iopub.status.idle": "2022-05-05T17:51:49.595090Z",
     "shell.execute_reply": "2022-05-05T17:51:49.594047Z"
    },
    "papermill": {
     "duration": 6.622935,
     "end_time": "2022-05-05T17:51:49.597581",
     "exception": false,
     "start_time": "2022-05-05T17:51:42.974646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:49.526369: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Create a network with 1 linear unit\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=1, input_shape=[3])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823009aa",
   "metadata": {
    "papermill": {
     "duration": 0.005333,
     "end_time": "2022-05-05T17:51:49.609261",
     "exception": false,
     "start_time": "2022-05-05T17:51:49.603928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "With the first argument, `units`, we define how many outputs we want. In this case we are just predicting `'calories'`, so we'll use `units=1`. \n",
    "\n",
    "With the second argument, `input_shape`, we tell Keras the dimensions of the inputs. Setting `input_shape=[3]` ensures the model will accept three features as input (`'sugars'`, `'fiber'`, and `'protein'`).\n",
    "\n",
    "This model is now ready to be fit to training data!\n",
    "\n",
    "<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #ebf9ff; padding: 1em; margin:24px;\">\n",
    "    <strong>Why is <code>input_shape</code> a Python list?</strong><br>\n",
    "The data we'll use in this course will be tabular data, like in a Pandas dataframe. We'll have one input for each feature in the dataset. The features are arranged by column, so we'll always have <code>input_shape=[num_columns]</code>.\n",
    "\n",
    "The reason Keras uses a list here is to permit use of more complex datasets. Image data, for instance, might need three dimensions: <code>[height, width, channels]</code>.\n",
    "</blockquote>\n",
    "\n",
    "# Your Turn #\n",
    "\n",
    "[**Define a linear model**](https://www.kaggle.com/kernels/fork/11887334) for the *Red Wine Quality* dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a71cf3",
   "metadata": {
    "papermill": {
     "duration": 0.005218,
     "end_time": "2022-05-05T17:51:49.620088",
     "exception": false,
     "start_time": "2022-05-05T17:51:49.614870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-deep-learning/discussion) to chat with other learners.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61455f0c",
   "metadata": {
    "papermill": {
     "duration": 0.005178,
     "end_time": "2022-05-05T17:51:14.787015",
     "exception": false,
     "start_time": "2022-05-05T17:51:14.781837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction #\n",
    "\n",
    "In this lesson we're going to see how we can build neural networks capable of learning the complex kinds of relationships deep neural nets are famous for.\n",
    "\n",
    "The key idea here is *modularity*, building up a complex network from simpler functional units. We've seen how a linear unit computes a linear function -- now we'll see how to combine and modify these single units to model more complex relationships.\n",
    "\n",
    "# Layers #\n",
    "\n",
    "Neural networks typically organize their neurons into **layers**. When we collect together linear units having a common set of inputs we get a **dense** layer.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/2MA4iMV.png\" width=\"300\" alt=\"A stack of three circles in an input layer connected to two circles in a dense layer.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>A dense layer of two linear units receiving two inputs and a bias.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "You could think of each layer in a neural network as performing some kind of relatively simple transformation. Through a deep stack of layers, a neural network can transform its inputs in more and more complex ways. In a well-trained neural network, each layer is a transformation getting us a little bit closer to a solution.\n",
    "\n",
    "<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #ebf9ff; padding: 1em; margin:24px;\">\n",
    "    <strong>Many Kinds of Layers</strong><br>\n",
    "A \"layer\" in Keras is a very general kind of thing. A layer can be, essentially, any kind of <em>data transformation</em>. Many layers, like the <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\">convolutional</a> and <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN\">recurrent</a> layers, transform data through use of neurons and differ primarily in the pattern of connections they form. Others though are used for <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\">feature engineering</a> or just <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add\">simple arithmetic</a>. There's a whole world of layers to discover -- <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers\">check them out</a>!\n",
    "</blockquote>\n",
    "\n",
    "# The Activation Function #\n",
    "\n",
    "It turns out, however, that two dense layers with nothing in between are no better than a single dense layer by itself. Dense layers by themselves can never move us out of the world of lines and planes. What we need is something *nonlinear*. What we need are activation functions.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/OLSUEYT.png\" width=\"400\" alt=\" \">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>Without activation functions, neural networks can only learn linear relationships. In order to fit curves, we'll need to use activation functions. \n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "An **activation function** is simply some function we apply to each of a layer's outputs (its *activations*). The most common is the *rectifier* function $max(0, x)$.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/aeIyAlF.png\" width=\"400\" alt=\"A graph of the rectifier function. The line y=x when x>0 and y=0 when x<0, making a 'hinge' shape like '_/'.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "The rectifier function has a graph that's a line with the negative part \"rectified\" to zero. Applying the function to the outputs of a neuron will put a *bend* in the data, moving us away from simple lines.\n",
    "\n",
    "When we attach the rectifier to a linear unit, we get a **rectified linear unit** or **ReLU**. (For this reason, it's common to call the rectifier function the \"ReLU function\".)  Applying a ReLU activation to a linear unit means the output becomes `max(0, w * x + b)`, which we might draw in a diagram like:\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/eFry7Yu.png\" width=\"250\" alt=\"Diagram of a single ReLU. Like a linear unit, but instead of a '+' symbol we now have a hinge '_/'. \">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>A rectified linear unit.\n",
    "</center></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b116abd",
   "metadata": {
    "papermill": {
     "duration": 0.003773,
     "end_time": "2022-05-05T17:51:14.795064",
     "exception": false,
     "start_time": "2022-05-05T17:51:14.791291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stacking Dense Layers #\n",
    "\n",
    "Now that we have some nonlinearity, let's see how we can stack layers to get complex data transformations.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/Y5iwFQZ.png\" width=\"450\" alt=\"An input layer, two hidden layers, and a final linear layer.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>A stack of dense layers makes a \"fully-connected\" network.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "The layers before the output layer are sometimes called **hidden** since we never see their outputs directly.\n",
    "\n",
    "Now, notice that the final (output) layer is a linear unit (meaning, no activation function). That makes this network appropriate to a regression task, where we are trying to predict some arbitrary numeric value. Other tasks (like classification) might require an activation function on the output.\n",
    "\n",
    "## Building Sequential Models ##\n",
    "\n",
    "The `Sequential` model we've been using will connect together a list of layers in order from first to last: the first layer gets the input, the last layer produces the output. This creates the model in the figure above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fbbc9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:14.805256Z",
     "iopub.status.busy": "2022-05-05T17:51:14.804631Z",
     "iopub.status.idle": "2022-05-05T17:51:21.454352Z",
     "shell.execute_reply": "2022-05-05T17:51:21.453366Z"
    },
    "papermill": {
     "duration": 6.657357,
     "end_time": "2022-05-05T17:51:21.456591",
     "exception": false,
     "start_time": "2022-05-05T17:51:14.799234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:21.379316: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # the hidden ReLU layers\n",
    "    layers.Dense(units=4, activation='relu', input_shape=[2]),\n",
    "    layers.Dense(units=3, activation='relu'),\n",
    "    # the linear output layer \n",
    "    layers.Dense(units=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44adf86b",
   "metadata": {
    "papermill": {
     "duration": 0.004598,
     "end_time": "2022-05-05T17:51:21.466319",
     "exception": false,
     "start_time": "2022-05-05T17:51:21.461721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Be sure to pass all the layers together in a list, like `[layer, layer, layer, ...]`, instead of as separate arguments. To add an activation function to a layer, just give its name in the `activation` argument.\n",
    "\n",
    "# Your Turn #\n",
    "\n",
    "Now, [**create a deep neural network**](https://www.kaggle.com/kernels/fork/11887344) for the *Concrete* dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d97bc",
   "metadata": {
    "papermill": {
     "duration": 0.004254,
     "end_time": "2022-05-05T17:51:21.475016",
     "exception": false,
     "start_time": "2022-05-05T17:51:21.470762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-deep-learning/discussion) to chat with other learners.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2e1bc",
   "metadata": {
    "papermill": {
     "duration": 0.010959,
     "end_time": "2022-05-05T17:51:08.731570",
     "exception": false,
     "start_time": "2022-05-05T17:51:08.720611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction #\n",
    "\n",
    "In the first two lessons, we learned how to build fully-connected networks out of stacks of dense layers. When first created, all of the network's weights are set randomly -- the network doesn't \"know\" anything yet. In this lesson we're going to see how to train a neural network; we're going to see how neural networks *learn*.\n",
    "\n",
    "As with all machine learning tasks, we begin with a set of training data. Each example in the training data consists of some features (the inputs) together with an expected target (the output). Training the network means adjusting its weights in such a way that it can transform the features into the target. In the *80 Cereals* dataset, for instance, we want a network that can take each cereal's `'sugar'`, `'fiber'`, and `'protein'` content and produce a prediction for that cereal's `'calories'`. If we can successfully train a network to do that, its weights must represent in some way the relationship between those features and that target as expressed in the training data.\n",
    "\n",
    "In addition to the training data, we need two more things:\n",
    "- A \"loss function\" that measures how good the network's predictions are.\n",
    "- An \"optimizer\" that can tell the network how to change its weights.\n",
    "\n",
    "# The Loss Function #\n",
    "\n",
    "We've seen how to design an architecture for a network, but we haven't seen how to tell a network *what* problem to solve. This is the job of the loss function.\n",
    "\n",
    "The **loss function** measures the disparity between the the target's true value and the value the model predicts. \n",
    "\n",
    "Different problems call for different loss functions. We have been looking at **regression** problems, where the task is to predict some numerical value -- calories in *80 Cereals*, rating in *Red Wine Quality*. Other regression tasks might be predicting the price of a house or the fuel efficiency of a car.\n",
    "\n",
    "A common loss function for regression problems is the **mean absolute error** or **MAE**. For each prediction `y_pred`, MAE measures the disparity from the true target `y_true` by an absolute difference `abs(y_true - y_pred)`.\n",
    "\n",
    "The total MAE loss on a dataset is the mean of all these absolute differences.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/VDcvkZN.png\" width=\"500\" alt=\"A graph depicting error bars from data points to the fitted line..\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>The mean absolute error is the average length between the fitted curve and the data points.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "Besides MAE, other loss functions you might see for regression problems are the mean-squared error (MSE) or the Huber loss (both available in Keras).\n",
    "\n",
    "During training, the model will use the loss function as a guide for finding the correct values of its weights (lower loss is better). In other words, the loss function tells the network its objective.\n",
    "\n",
    "# The Optimizer - Stochastic Gradient Descent #\n",
    "\n",
    "We've described the problem we want the network to solve, but now we need to say *how* to solve it. This is the job of the **optimizer**. The optimizer is an algorithm that adjusts the weights to minimize the loss.\n",
    "\n",
    "Virtually all of the optimization algorithms used in deep learning belong to a family called **stochastic gradient descent**. They are iterative algorithms that train a network in steps. One **step** of training goes like this:\n",
    "1. Sample some training data and run it through the network to make predictions.\n",
    "2. Measure the loss between the predictions and the true values.\n",
    "3. Finally, adjust the weights in a direction that makes the loss smaller.\n",
    "\n",
    "Then just do this over and over until the loss is as small as you like (or until it won't decrease any further.)\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/rFI1tIk.gif\" width=\"1600\" alt=\"Fitting a line batch by batch. The loss decreases and the weights approach their true values.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>Training a neural network with Stochastic Gradient Descent.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "Each iteration's sample of training data is called a **minibatch** (or often just \"batch\"), while a complete round of the training data is called an **epoch**. The number of epochs you train for is how many times the network will see each training example.\n",
    "\n",
    "The animation shows the linear model from Lesson 1 being trained with SGD. The pale red dots depict the entire training set, while the solid red dots are the minibatches. Every time SGD sees a new minibatch, it will shift the weights (`w` the slope and `b` the y-intercept) toward their correct values on that batch. Batch after batch, the line eventually converges to its best fit. You can see that the loss gets smaller as the weights get closer to their true values.\n",
    "\n",
    "## Learning Rate and Batch Size ##\n",
    "\n",
    "Notice that the line only makes a small shift in the direction of each batch (instead of moving all the way). The size of these shifts is determined by the **learning rate**. A smaller learning rate means the network needs to see more minibatches before its weights converge to their best values.\n",
    "\n",
    "The learning rate and the size of the minibatches are the two parameters that have the largest effect on how the SGD training proceeds. Their interaction is often subtle and the right choice for these parameters isn't always obvious. (We'll explore these effects in the exercise.)\n",
    "\n",
    "Fortunately, for most work it won't be necessary to do an extensive hyperparameter search to get satisfactory results. **Adam** is an SGD algorithm that has an adaptive learning rate that makes it suitable for most problems without any parameter tuning (it is \"self tuning\", in a sense). Adam is a great general-purpose optimizer.\n",
    "\n",
    "## Adding the Loss and Optimizer ##\n",
    "\n",
    "After defining a model, you can add a loss function and optimizer with the model's `compile` method:\n",
    "\n",
    "```\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\",\n",
    ")\n",
    "```\n",
    "\n",
    "Notice that we are able to specify the loss and optimizer with just a string. You can also access these directly through the Keras API -- if you wanted to tune parameters, for instance -- but for us, the defaults will work fine.\n",
    "\n",
    "<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #ebf9ff; padding: 1em; margin:24px;\">\n",
    "    <strong>What's In a Name?</strong><br>\n",
    "The <strong>gradient</strong> is a vector that tells us in what direction the weights need to go. More precisely, it tells us how to change the weights to make the loss change <em>fastest</em>. We call our process gradient <strong>descent</strong> because it uses the gradient to <em>descend</em> the loss curve towards a minimum. <strong>Stochastic</strong> means \"determined by chance.\" Our training is <em>stochastic</em> because the minibatches are <em>random samples</em> from the dataset. And that's why it's called SGD!\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c4a25",
   "metadata": {
    "papermill": {
     "duration": 0.010151,
     "end_time": "2022-05-05T17:51:08.752265",
     "exception": false,
     "start_time": "2022-05-05T17:51:08.742114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Example - Red Wine Quality #\n",
    "\n",
    "Now we know everything we need to start training deep learning models. So let's see it in action! We'll use the *Red Wine Quality* dataset.\n",
    "\n",
    "This dataset consists of physiochemical measurements from about 1600 Portuguese red wines. Also included is a quality rating for each wine from blind taste-tests. How well can we predict a wine's perceived quality from these measurements?\n",
    "\n",
    "We've put all of the data preparation into this next hidden cell. It's not essential to what follows so feel free to skip it. One thing you might note for now though is that we've rescaled each feature to lie in the interval $[0, 1]$. As we'll discuss more in Lesson 5, neural networks tend to perform best when their inputs are on a common scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c07c35",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:08.775018Z",
     "iopub.status.busy": "2022-05-05T17:51:08.774551Z",
     "iopub.status.idle": "2022-05-05T17:51:08.845162Z",
     "shell.execute_reply": "2022-05-05T17:51:08.844128Z"
    },
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": 0.084257,
     "end_time": "2022-05-05T17:51:08.847376",
     "exception": false,
     "start_time": "2022-05-05T17:51:08.763119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>10.8</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.171</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.063</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1109           10.8             0.470         0.43            2.10      0.171   \n",
       "1032            8.1             0.820         0.00            4.10      0.095   \n",
       "1002            9.1             0.290         0.33            2.05      0.063   \n",
       "487            10.2             0.645         0.36            1.80      0.053   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1109                 27.0                  66.0  0.99820  3.17       0.76   \n",
       "1032                  5.0                  14.0  0.99854  3.36       0.53   \n",
       "1002                 13.0                  27.0  0.99516  3.26       0.84   \n",
       "487                   5.0                  14.0  0.99820  3.17       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "1109     10.8        6  \n",
       "1032      9.6        5  \n",
       "1002     11.7        7  \n",
       "487      10.0        6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "red_wine = pd.read_csv('../input/dl-course-data/red-wine.csv')\n",
    "\n",
    "# Create training and validation splits\n",
    "df_train = red_wine.sample(frac=0.7, random_state=0)\n",
    "df_valid = red_wine.drop(df_train.index)\n",
    "display(df_train.head(4))\n",
    "\n",
    "# Scale to [0, 1]\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)\n",
    "\n",
    "# Split features and target\n",
    "X_train = df_train.drop('quality', axis=1)\n",
    "X_valid = df_valid.drop('quality', axis=1)\n",
    "y_train = df_train['quality']\n",
    "y_valid = df_valid['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9113833",
   "metadata": {
    "papermill": {
     "duration": 0.010785,
     "end_time": "2022-05-05T17:51:08.870188",
     "exception": false,
     "start_time": "2022-05-05T17:51:08.859403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "How many inputs should this network have? We can discover this by looking at the number of columns in the data matrix. Be sure not to include the target (`'quality'`) here -- only the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef4df3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:08.894606Z",
     "iopub.status.busy": "2022-05-05T17:51:08.894218Z",
     "iopub.status.idle": "2022-05-05T17:51:08.899338Z",
     "shell.execute_reply": "2022-05-05T17:51:08.898198Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.019742,
     "end_time": "2022-05-05T17:51:08.900932",
     "exception": false,
     "start_time": "2022-05-05T17:51:08.881190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4685c",
   "metadata": {
    "papermill": {
     "duration": 0.011457,
     "end_time": "2022-05-05T17:51:08.924283",
     "exception": false,
     "start_time": "2022-05-05T17:51:08.912826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Eleven columns means eleven inputs.\n",
    "\n",
    "We've chosen a three-layer network with over 1500 neurons. This network should be capable of learning fairly complex relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a96768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:08.949955Z",
     "iopub.status.busy": "2022-05-05T17:51:08.949534Z",
     "iopub.status.idle": "2022-05-05T17:51:14.571233Z",
     "shell.execute_reply": "2022-05-05T17:51:14.570223Z"
    },
    "papermill": {
     "duration": 5.636819,
     "end_time": "2022-05-05T17:51:14.573031",
     "exception": false,
     "start_time": "2022-05-05T17:51:08.936212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:14.489438: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=[11]),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51116cd6",
   "metadata": {
    "papermill": {
     "duration": 0.013131,
     "end_time": "2022-05-05T17:51:14.599721",
     "exception": false,
     "start_time": "2022-05-05T17:51:14.586590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Deciding the architecture of your model should be part of a process. Start simple and use the validation loss as your guide. You'll learn more about model development in the exercises.\n",
    "\n",
    "After defining the model, we compile in the optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc991c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:14.626399Z",
     "iopub.status.busy": "2022-05-05T17:51:14.626146Z",
     "iopub.status.idle": "2022-05-05T17:51:14.638882Z",
     "shell.execute_reply": "2022-05-05T17:51:14.638090Z"
    },
    "papermill": {
     "duration": 0.027452,
     "end_time": "2022-05-05T17:51:14.640479",
     "exception": false,
     "start_time": "2022-05-05T17:51:14.613027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b519d2c",
   "metadata": {
    "papermill": {
     "duration": 0.011486,
     "end_time": "2022-05-05T17:51:14.664076",
     "exception": false,
     "start_time": "2022-05-05T17:51:14.652590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we're ready to start the training! We've told Keras to feed the optimizer 256 rows of the training data at a time (the `batch_size`) and to do that 10 times all the way through the dataset (the `epochs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201c9910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:14.689035Z",
     "iopub.status.busy": "2022-05-05T17:51:14.688785Z",
     "iopub.status.idle": "2022-05-05T17:51:17.800254Z",
     "shell.execute_reply": "2022-05-05T17:51:17.799259Z"
    },
    "papermill": {
     "duration": 3.126783,
     "end_time": "2022-05-05T17:51:17.802722",
     "exception": false,
     "start_time": "2022-05-05T17:51:14.675939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:14.768185: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 73ms/step - loss: 0.2626 - val_loss: 0.1382\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1382 - val_loss: 0.1243\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1246 - val_loss: 0.1180\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1141 - val_loss: 0.1096\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1127 - val_loss: 0.1091\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1096 - val_loss: 0.1044\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1049 - val_loss: 0.1025\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1054 - val_loss: 0.1021\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1016 - val_loss: 0.1010\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1004 - val_loss: 0.0975\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2cb27",
   "metadata": {
    "papermill": {
     "duration": 0.020275,
     "end_time": "2022-05-05T17:51:17.843301",
     "exception": false,
     "start_time": "2022-05-05T17:51:17.823026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can see that Keras will keep you updated on the loss as the model trains.\n",
    "\n",
    "Often, a better way to view the loss though is to plot it. The `fit` method in fact keeps a record of the loss produced during training in a `History` object. We'll convert the data to a Pandas dataframe, which makes the plotting easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90d01429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:17.884506Z",
     "iopub.status.busy": "2022-05-05T17:51:17.884122Z",
     "iopub.status.idle": "2022-05-05T17:51:18.091248Z",
     "shell.execute_reply": "2022-05-05T17:51:18.090377Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.230129,
     "end_time": "2022-05-05T17:51:18.093226",
     "exception": false,
     "start_time": "2022-05-05T17:51:17.863097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history.history)\n",
    "# use Pandas native plot method\n",
    "history_df['loss'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7545fb3a",
   "metadata": {
    "papermill": {
     "duration": 0.031308,
     "end_time": "2022-05-05T17:51:18.156210",
     "exception": false,
     "start_time": "2022-05-05T17:51:18.124902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice how the loss levels off as the epochs go by. When the loss curve becomes horizontal like that, it means the model has learned all it can and there would be no reason continue for additional epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590cd28b",
   "metadata": {
    "papermill": {
     "duration": 0.031178,
     "end_time": "2022-05-05T17:51:18.221255",
     "exception": false,
     "start_time": "2022-05-05T17:51:18.190077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Your Turn #\n",
    "\n",
    "Now, [**use stochastic gradient descent**](https://www.kaggle.com/kernels/fork/11887330) to train your network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89455fd7",
   "metadata": {
    "papermill": {
     "duration": 0.020212,
     "end_time": "2022-05-05T17:51:18.262633",
     "exception": false,
     "start_time": "2022-05-05T17:51:18.242421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-deep-learning/discussion) to chat with other learners.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56331f78",
   "metadata": {
    "papermill": {
     "duration": 0.007754,
     "end_time": "2022-05-05T17:51:04.227425",
     "exception": false,
     "start_time": "2022-05-05T17:51:04.219671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction #\n",
    "\n",
    "Recall from the example in the previous lesson that Keras will keep a history of the training and validation loss over the epochs that it is training the model. In this lesson, we're going to learn how to interpret these learning curves and how we can use them to guide model development. In particular, we'll examine at the learning curves for evidence of *underfitting* and *overfitting* and look at a couple of strategies for correcting it.\n",
    "\n",
    "# Interpreting the Learning Curves #\n",
    "\n",
    "You might think about the information in the training data as being of two kinds: *signal* and *noise*. The signal is the part that generalizes, the part that can help our model make predictions from new data. The noise is that part that is *only* true of the training data; the noise is all of the random fluctuation that comes from data in the real-world or all of the incidental, non-informative patterns that can't actually help the model make predictions. The noise is the part might look useful but really isn't.\n",
    "\n",
    "We train a model by choosing weights or parameters that minimize the loss on a training set. You might know, however, that to accurately assess a model's performance, we need to evaluate it on a new set of data, the *validation* data. (You could see our lesson on [model validation](https://www.kaggle.com/dansbecker/model-validation) in *Introduction to Machine Learning* for a review.)\n",
    "\n",
    "When we train a model we've been plotting the loss on the training set epoch by epoch. To this we'll add a plot the validation data too. These plots we call the **learning curves**. To train deep learning models effectively, we need to be able to interpret them.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/tHiVFnM.png\" width=\"500\" alt=\"A graph of training and validation loss.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>The validation loss gives an estimate of the expected error on unseen data.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "Now, the training loss will go down either when the model learns signal or when it learns noise. But the validation loss will go down only when the model learns signal. (Whatever noise the model learned from the training set won't generalize to new data.) So, when a model learns signal both curves go down, but when it learns noise a *gap* is created in the curves. The size of the gap tells you how much noise the model has learned.\n",
    "\n",
    "Ideally, we would create models that learn all of the signal and none of the noise. This will practically never happen. Instead we make a trade. We can get the model to learn more signal at the cost of learning more noise. So long as the trade is in our favor, the validation loss will continue to decrease. After a certain point, however, the trade can turn against us, the cost exceeds the benefit, and the validation loss begins to rise.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/eUF6mfo.png\" width=\"600\" alt=\"Two graphs. On the left, a line through a few data points with the true fit a parabola. On the right, a curve running through each datapoint with the true fit a parabola.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>Underfitting and overfitting.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "This trade-off indicates that there can be two problems that occur when training a model: not enough signal or too much noise. **Underfitting** the training set is when the loss is not as low as it could be because the model hasn't learned enough *signal*. **Overfitting** the training set is when the loss is not as low as it could be because the model learned too much *noise*. The trick to training deep learning models is finding the best balance between the two.\n",
    "\n",
    "We'll look at a couple ways of getting more signal out of the training data while reducing the amount of noise.\n",
    "\n",
    "# Capacity #\n",
    "\n",
    "A model's **capacity** refers to the size and complexity of the patterns it is able to learn. For neural networks, this will largely be determined by how many neurons it has and how they are connected together. If it appears that your network is underfitting the data, you should try increasing its capacity.\n",
    "\n",
    "You can increase the capacity of a network either by making it *wider* (more units to existing layers) or by making it *deeper* (adding more layers). Wider networks have an easier time learning more linear relationships, while deeper networks prefer more nonlinear ones. Which is better just depends on the dataset.\n",
    "\n",
    "```\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "wider = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "deeper = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "```\n",
    "\n",
    "You'll explore how the capacity of a network can affect its performance in the exercise.\n",
    "\n",
    "# Early Stopping #\n",
    "\n",
    "We mentioned that when a model is too eagerly learning noise, the validation loss may start to increase during training. To prevent this, we can simply stop the training whenever it seems the validation loss isn't decreasing anymore. Interrupting the training this way is called **early stopping**.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/eP0gppr.png\" width=500 alt=\"A graph of the learning curves with early stopping at the minimum validation loss, underfitting to the left of it and overfitting to the right.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>We keep the model where the validation loss is at a minimum.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "Once we detect that the validation loss is starting to rise again, we can reset the weights back to where the minimum occured. This ensures that the model won't continue to learn noise and overfit the data.\n",
    "\n",
    "Training with early stopping also means we're in less danger of stopping the training too early, before the network has finished learning signal. So besides preventing overfitting from training too long, early stopping can also prevent *underfitting* from not training long enough. Just set your training epochs to some large number (more than you'll need), and early stopping will take care of the rest.\n",
    "\n",
    "## Adding Early Stopping ##\n",
    "\n",
    "In Keras, we include early stopping in our training through a callback. A **callback** is just a function you want run every so often while the network trains. The early stopping callback will run after every epoch. (Keras has [a variety of useful callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks) pre-defined, but you can [define your own](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LambdaCallback), too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da673c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:04.243564Z",
     "iopub.status.busy": "2022-05-05T17:51:04.242384Z",
     "iopub.status.idle": "2022-05-05T17:51:10.619925Z",
     "shell.execute_reply": "2022-05-05T17:51:10.619159Z"
    },
    "papermill": {
     "duration": 6.388361,
     "end_time": "2022-05-05T17:51:10.622594",
     "exception": false,
     "start_time": "2022-05-05T17:51:04.234233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa1bd80",
   "metadata": {
    "papermill": {
     "duration": 0.006731,
     "end_time": "2022-05-05T17:51:10.636362",
     "exception": false,
     "start_time": "2022-05-05T17:51:10.629631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "These parameters say: \"If there hasn't been at least an improvement of 0.001 in the validation loss over the previous 20 epochs, then stop the training and keep the best model you found.\" It can sometimes be hard to tell if the validation loss is rising due to overfitting or just due to random batch variation. The parameters allow us to set some allowances around when to stop.\n",
    "\n",
    "As we'll see in our example, we'll pass this callback to the `fit` method along with the loss and optimizer.\n",
    "\n",
    "# Example - Train a Model with Early Stopping #\n",
    "\n",
    "Let's continue developing the model from the example in the last tutorial. We'll increase the capacity of that network but also add an early-stopping callback to prevent overfitting.\n",
    "\n",
    "Here's the data prep again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2269e7b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:10.651807Z",
     "iopub.status.busy": "2022-05-05T17:51:10.651224Z",
     "iopub.status.idle": "2022-05-05T17:51:10.707016Z",
     "shell.execute_reply": "2022-05-05T17:51:10.706010Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.0661,
     "end_time": "2022-05-05T17:51:10.709178",
     "exception": false,
     "start_time": "2022-05-05T17:51:10.643078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>10.8</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.171</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.063</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1109           10.8             0.470         0.43            2.10      0.171   \n",
       "1032            8.1             0.820         0.00            4.10      0.095   \n",
       "1002            9.1             0.290         0.33            2.05      0.063   \n",
       "487            10.2             0.645         0.36            1.80      0.053   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1109                 27.0                  66.0  0.99820  3.17       0.76   \n",
       "1032                  5.0                  14.0  0.99854  3.36       0.53   \n",
       "1002                 13.0                  27.0  0.99516  3.26       0.84   \n",
       "487                   5.0                  14.0  0.99820  3.17       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "1109     10.8        6  \n",
       "1032      9.6        5  \n",
       "1002     11.7        7  \n",
       "487      10.0        6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "red_wine = pd.read_csv('../input/dl-course-data/red-wine.csv')\n",
    "\n",
    "# Create training and validation splits\n",
    "df_train = red_wine.sample(frac=0.7, random_state=0)\n",
    "df_valid = red_wine.drop(df_train.index)\n",
    "display(df_train.head(4))\n",
    "\n",
    "# Scale to [0, 1]\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)\n",
    "\n",
    "# Split features and target\n",
    "X_train = df_train.drop('quality', axis=1)\n",
    "X_valid = df_valid.drop('quality', axis=1)\n",
    "y_train = df_train['quality']\n",
    "y_valid = df_valid['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef05d0d",
   "metadata": {
    "papermill": {
     "duration": 0.007644,
     "end_time": "2022-05-05T17:51:10.724994",
     "exception": false,
     "start_time": "2022-05-05T17:51:10.717350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let's increase the capacity of the network. We'll go for a fairly large network, but rely on the callback to halt the training once the validation loss shows signs of increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5879eb27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:10.742350Z",
     "iopub.status.busy": "2022-05-05T17:51:10.742044Z",
     "iopub.status.idle": "2022-05-05T17:51:10.883862Z",
     "shell.execute_reply": "2022-05-05T17:51:10.883187Z"
    },
    "papermill": {
     "duration": 0.152829,
     "end_time": "2022-05-05T17:51:10.885742",
     "exception": false,
     "start_time": "2022-05-05T17:51:10.732913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:10.786134: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=[11]),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572cf81e",
   "metadata": {
    "papermill": {
     "duration": 0.008112,
     "end_time": "2022-05-05T17:51:10.902009",
     "exception": false,
     "start_time": "2022-05-05T17:51:10.893897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After defining the callback, add it as an argument in `fit` (you can have several, so put it in a list). Choose a large number of epochs when using early stopping, more than you'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06bc09c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:10.920382Z",
     "iopub.status.busy": "2022-05-05T17:51:10.919891Z",
     "iopub.status.idle": "2022-05-05T17:51:18.101965Z",
     "shell.execute_reply": "2022-05-05T17:51:18.101037Z"
    },
    "papermill": {
     "duration": 7.193677,
     "end_time": "2022-05-05T17:51:18.103906",
     "exception": false,
     "start_time": "2022-05-05T17:51:10.910229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:11.014810: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss: 0.09168479591608047\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=256,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping], # put your callbacks in a list\n",
    "    verbose=0,  # turn off training log\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f7a4b",
   "metadata": {
    "papermill": {
     "duration": 0.00932,
     "end_time": "2022-05-05T17:51:18.122899",
     "exception": false,
     "start_time": "2022-05-05T17:51:18.113579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And sure enough, Keras stopped the training well before the full 500 epochs!\n",
    "\n",
    "# Your Turn #\n",
    "\n",
    "Now [**predict how popular a song is**](https://www.kaggle.com/kernels/fork/11906770) with the *Spotify* dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49853072",
   "metadata": {
    "papermill": {
     "duration": 0.009291,
     "end_time": "2022-05-05T17:51:18.141769",
     "exception": false,
     "start_time": "2022-05-05T17:51:18.132478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-deep-learning/discussion) to chat with other learners.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b1226",
   "metadata": {
    "papermill": {
     "duration": 0.008322,
     "end_time": "2022-05-05T17:51:18.977696",
     "exception": false,
     "start_time": "2022-05-05T17:51:18.969374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction #\n",
    "\n",
    "There's more to the world of deep learning than just dense layers. There are dozens of kinds of layers you might add to a model. (Try browsing through the [Keras docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/) for a sample!) Some are like dense layers and define connections between neurons, and others can do preprocessing or transformations of other sorts.\n",
    "\n",
    "In this lesson, we'll learn about a two kinds of special layers, not containing any neurons themselves, but that add some functionality that can sometimes benefit a model in various ways. Both are commonly used in modern architectures.\n",
    "\n",
    "# Dropout #\n",
    "\n",
    "The first of these is the \"dropout layer\", which can help correct overfitting.\n",
    "\n",
    "In the last lesson we talked about how overfitting is caused by the network learning spurious patterns in the training data. To recognize these spurious patterns a network will often rely on very a specific combinations of weight, a kind of \"conspiracy\" of weights. Being so specific, they tend to be fragile: remove one and the conspiracy falls apart.\n",
    "\n",
    "This is the idea behind **dropout**. To break up these conspiracies, we randomly *drop out* some fraction of a layer's input units every step of training, making it much harder for the network to learn those spurious patterns in the training data. Instead, it has to search for broad, general patterns, whose weight patterns tend to be more robust.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/a86utxY.gif\" width=\"600\" alt=\"An animation of a network cycling through various random dropout configurations.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>Here, 50% dropout has been added between the two hidden layers.</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "You could also think about dropout as creating a kind of *ensemble* of networks. The predictions will no longer be made by one big network, but instead by a committee of smaller networks. Individuals in the committee tend to make different kinds of mistakes, but be right at the same time, making the committee as a whole better than any individual. (If you're familiar with random forests as an ensemble of decision trees, it's the same idea.)\n",
    "\n",
    "## Adding Dropout ##\n",
    "\n",
    "In Keras, the dropout rate argument `rate` defines what percentage of the input units to shut off. Put the `Dropout` layer just before the layer you want the dropout applied to:\n",
    "\n",
    "```\n",
    "keras.Sequential([\n",
    "    # ...\n",
    "    layers.Dropout(rate=0.3), # apply 30% dropout to the next layer\n",
    "    layers.Dense(16),\n",
    "    # ...\n",
    "])\n",
    "```\n",
    "\n",
    "# Batch Normalization #\n",
    "\n",
    "The next special layer we'll look at performs \"batch normalization\" (or \"batchnorm\"), which can help correct training that is slow or unstable.\n",
    "\n",
    "With neural networks, it's generally a good idea to put all of your data on a common scale, perhaps with something like scikit-learn's [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) or [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html). The reason is that SGD will shift the network weights in proportion to how large an activation the data produces. Features that tend to produce activations of very different sizes can make for unstable training behavior.\n",
    "\n",
    "Now, if it's good to normalize the data before it goes into the network, maybe also normalizing inside the network would be better! In fact, we have a special kind of layer that can do this, the **batch normalization layer**. A batch normalization layer looks at each batch as it comes in, first normalizing the batch with its own mean and standard deviation, and then also putting the data on a new scale with two trainable rescaling parameters. Batchnorm, in effect, performs a kind of coordinated rescaling of its inputs.\n",
    "\n",
    "Most often, batchnorm is added as an aid to the optimization process (though it can sometimes also help prediction performance). Models with batchnorm tend to need fewer epochs to complete training. Moreover, batchnorm can also fix various problems that can cause the training to get \"stuck\". Consider adding batch normalization to your models, especially if you're having trouble during training.\n",
    "\n",
    "## Adding Batch Normalization ##\n",
    "\n",
    "It seems that batch normalization can be used at almost any point in a network. You can put it after a layer...\n",
    "\n",
    "```\n",
    "layers.Dense(16, activation='relu'),\n",
    "layers.BatchNormalization(),\n",
    "```\n",
    "\n",
    "... or between a layer and its activation function:\n",
    "\n",
    "```\n",
    "layers.Dense(16),\n",
    "layers.BatchNormalization(),\n",
    "layers.Activation('relu'),\n",
    "```\n",
    "\n",
    "And if you add it as the first layer of your network it can act as a kind of adaptive preprocessor, standing in for something like Sci-Kit Learn's `StandardScaler`.\n",
    "\n",
    "# Example - Using Dropout and Batch Normalization #\n",
    "\n",
    "Let's continue developing the *Red Wine* model. Now we'll increase the capacity even more, but add dropout to control overfitting and batch normalization to speed up optimization. This time, we'll also leave off standardizing the data, to demonstrate how batch normalization can stabalize the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d14f52",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:18.994254Z",
     "iopub.status.busy": "2022-05-05T17:51:18.993861Z",
     "iopub.status.idle": "2022-05-05T17:51:19.044131Z",
     "shell.execute_reply": "2022-05-05T17:51:19.043379Z"
    },
    "papermill": {
     "duration": 0.061793,
     "end_time": "2022-05-05T17:51:19.046929",
     "exception": false,
     "start_time": "2022-05-05T17:51:18.985136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "red_wine = pd.read_csv('../input/dl-course-data/red-wine.csv')\n",
    "\n",
    "# Create training and validation splits\n",
    "df_train = red_wine.sample(frac=0.7, random_state=0)\n",
    "df_valid = red_wine.drop(df_train.index)\n",
    "\n",
    "# Split features and target\n",
    "X_train = df_train.drop('quality', axis=1)\n",
    "X_valid = df_valid.drop('quality', axis=1)\n",
    "y_train = df_train['quality']\n",
    "y_valid = df_valid['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd404fa",
   "metadata": {
    "papermill": {
     "duration": 0.007086,
     "end_time": "2022-05-05T17:51:19.061794",
     "exception": false,
     "start_time": "2022-05-05T17:51:19.054708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When adding dropout, you may need to increase the number of units in your `Dense` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c396a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:19.078264Z",
     "iopub.status.busy": "2022-05-05T17:51:19.077968Z",
     "iopub.status.idle": "2022-05-05T17:51:25.763527Z",
     "shell.execute_reply": "2022-05-05T17:51:25.762365Z"
    },
    "papermill": {
     "duration": 6.696835,
     "end_time": "2022-05-05T17:51:25.766053",
     "exception": false,
     "start_time": "2022-05-05T17:51:19.069218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:25.610426: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=[11]),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d16491",
   "metadata": {
    "papermill": {
     "duration": 0.00773,
     "end_time": "2022-05-05T17:51:25.782261",
     "exception": false,
     "start_time": "2022-05-05T17:51:25.774531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There's nothing to change this time in how we set up the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc64a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:25.800457Z",
     "iopub.status.busy": "2022-05-05T17:51:25.800150Z",
     "iopub.status.idle": "2022-05-05T17:51:59.838233Z",
     "shell.execute_reply": "2022-05-05T17:51:59.837115Z"
    },
    "papermill": {
     "duration": 34.059644,
     "end_time": "2022-05-05T17:51:59.850357",
     "exception": false,
     "start_time": "2022-05-05T17:51:25.790713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:25.917123: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=256,\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "\n",
    "# Show the learning curves\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeb6b8d",
   "metadata": {
    "papermill": {
     "duration": 0.009431,
     "end_time": "2022-05-05T17:51:59.869469",
     "exception": false,
     "start_time": "2022-05-05T17:51:59.860038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You'll typically get better performance if you standardize your data before using it for training. That we were able to use the raw data at all, however, shows how effective batch normalization can be on more difficult datasets.\n",
    "\n",
    "# Your Turn #\n",
    "\n",
    "Move on to [**improve predictions**](https://www.kaggle.com/kernels/fork/11887342) on the *Spotify* dataset with dropout and see how batch normalization can help with difficult datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3291f5",
   "metadata": {
    "papermill": {
     "duration": 0.009914,
     "end_time": "2022-05-05T17:51:59.889976",
     "exception": false,
     "start_time": "2022-05-05T17:51:59.880062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-deep-learning/discussion) to chat with other learners.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a60d1",
   "metadata": {
    "papermill": {
     "duration": 0.012641,
     "end_time": "2022-05-05T17:51:37.673131",
     "exception": false,
     "start_time": "2022-05-05T17:51:37.660490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction #\n",
    "\n",
    "So far in this course, we've learned about how neural networks can solve regression problems. Now we're going to apply neural networks to another common machine learning problem: classification. Most everything we've learned up until now still applies. The main difference is in the loss function we use and in what kind of outputs we want the final layer to produce.\n",
    "\n",
    "# Binary Classification #\n",
    "\n",
    "Classification into one of two classes is a common machine learning problem. You might want to predict whether or not a customer is likely to make a purchase, whether or not a credit card transaction was fraudulent, whether deep space signals show evidence of a new planet, or a medical test evidence of a disease. These are all **binary classification** problems.\n",
    "\n",
    "In your raw data, the classes might be represented by strings like `\"Yes\"` and `\"No\"`, or `\"Dog\"` and `\"Cat\"`. Before using this data we'll assign a **class label**: one class will be `0` and the other will be `1`. Assigning numeric labels puts the data in a form a neural network can use.\n",
    "\n",
    "# Accuracy and Cross-Entropy #\n",
    "\n",
    "**Accuracy** is one of the many metrics in use for measuring success on a classification problem. Accuracy is the ratio of correct predictions to total predictions: `accuracy = number_correct / total`. A model that always predicted correctly would have an accuracy score of `1.0`. All else being equal, accuracy is a reasonable metric to use whenever the classes in the dataset occur with about the same frequency.\n",
    "\n",
    "The problem with accuracy (and most other classification metrics) is that it can't be used as a loss function. SGD needs a loss function that changes smoothly, but accuracy, being a ratio of counts, changes in \"jumps\". So, we have to choose a substitute to act as the loss function. This substitute is the *cross-entropy* function.\n",
    "\n",
    "Now, recall that the loss function defines the *objective* of the network during training. With regression, our goal was to minimize the distance between the expected outcome and the predicted outcome. We chose MAE to measure this distance.\n",
    "\n",
    "For classification, what we want instead is a distance between *probabilities*, and this is what cross-entropy provides. **Cross-entropy** is a sort of measure for the distance from one probability distribution to another.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/DwVV9bR.png\" width=\"400\" alt=\"Graphs of accuracy and cross-entropy.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>Cross-entropy penalizes incorrect probability predictions.</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "The idea is that we want our network to predict the correct class with probability `1.0`. The further away the predicted probability is from `1.0`, the greater will be the cross-entropy loss.\n",
    "\n",
    "The technical reasons we use cross-entropy are a bit subtle, but the main thing to take away from this section is just this: use cross-entropy for a classification loss; other metrics you might care about (like accuracy) will tend to improve along with it.\n",
    "\n",
    "# Making Probabilities with the Sigmoid Function #\n",
    "\n",
    "The cross-entropy and accuracy functions both require probabilities as inputs, meaning, numbers from 0 to 1. To covert the real-valued outputs produced by a dense layer into probabilities, we attach a new kind of activation function, the **sigmoid activation**.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/FYbRvJo.png\" width=\"400\" alt=\"The sigmoid graph is an 'S' shape with horizontal asymptotes at 0 to the left and 1 to the right. \">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>The sigmoid function maps real numbers into the interval $[0, 1]$.</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "To get the final class prediction, we define a *threshold* probability. Typically this will be 0.5, so that rounding will give us the correct class: below 0.5 means the class with label 0 and 0.5 or above means the class with label 1. A 0.5 threshold is what Keras uses by default with its [accuracy metric](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy).\n",
    "\n",
    "# Example - Binary Classification #\n",
    "\n",
    "Now let's try it out!\n",
    "\n",
    "The [Ionosphere](https://archive.ics.uci.edu/ml/datasets/Ionosphere) dataset contains features obtained from radar signals focused on the ionosphere layer of the Earth's atmosphere. The task is to determine whether the signal shows the presence of some object, or just empty air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f4564e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:37.700741Z",
     "iopub.status.busy": "2022-05-05T17:51:37.699520Z",
     "iopub.status.idle": "2022-05-05T17:51:37.799711Z",
     "shell.execute_reply": "2022-05-05T17:51:37.798769Z"
    },
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": 0.117612,
     "end_time": "2022-05-05T17:51:37.802143",
     "exception": false,
     "start_time": "2022-05-05T17:51:37.684531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2       V3       V4       V5       V6       V7       V8       V9  \\\n",
       "1   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "2   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "3   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "4   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "5   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "       V10  ...      V26      V27      V28      V29      V30      V31  \\\n",
       "1  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "2 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "3  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "4  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "5 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "       V32      V33      V34  Class  \n",
       "1 -0.54487  0.18641 -0.45300   good  \n",
       "2 -0.06288 -0.13738 -0.02447    bad  \n",
       "3 -0.24180  0.56045 -0.38238   good  \n",
       "4  1.00000 -0.32382  1.00000    bad  \n",
       "5 -0.59573 -0.04608 -0.65697   good  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "ion = pd.read_csv('../input/dl-course-data/ion.csv', index_col=0)\n",
    "display(ion.head())\n",
    "\n",
    "df = ion.copy()\n",
    "df['Class'] = df['Class'].map({'good': 0, 'bad': 1})\n",
    "\n",
    "df_train = df.sample(frac=0.7, random_state=0)\n",
    "df_valid = df.drop(df_train.index)\n",
    "\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)\n",
    "df_train.dropna(axis=1, inplace=True) # drop the empty feature in column 2\n",
    "df_valid.dropna(axis=1, inplace=True)\n",
    "\n",
    "X_train = df_train.drop('Class', axis=1)\n",
    "X_valid = df_valid.drop('Class', axis=1)\n",
    "y_train = df_train['Class']\n",
    "y_valid = df_valid['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c5021",
   "metadata": {
    "papermill": {
     "duration": 0.010477,
     "end_time": "2022-05-05T17:51:37.824025",
     "exception": false,
     "start_time": "2022-05-05T17:51:37.813548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll define our model just like we did for the regression tasks, with one exception. In the final layer include a `'sigmoid'` activation so that the model will produce class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fde980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:37.847261Z",
     "iopub.status.busy": "2022-05-05T17:51:37.846929Z",
     "iopub.status.idle": "2022-05-05T17:51:44.267041Z",
     "shell.execute_reply": "2022-05-05T17:51:44.265973Z"
    },
    "papermill": {
     "duration": 6.43411,
     "end_time": "2022-05-05T17:51:44.268949",
     "exception": false,
     "start_time": "2022-05-05T17:51:37.834839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:44.181353: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation='relu', input_shape=[33]),\n",
    "    layers.Dense(4, activation='relu'),    \n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589ad9c",
   "metadata": {
    "papermill": {
     "duration": 0.011413,
     "end_time": "2022-05-05T17:51:44.292372",
     "exception": false,
     "start_time": "2022-05-05T17:51:44.280959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Add the cross-entropy loss and accuracy metric to the model with its `compile` method. For two-class problems, be sure to use `'binary'` versions. (Problems with more classes will be slightly different.) The Adam optimizer works great for classification too, so we'll stick with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21df474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:44.317995Z",
     "iopub.status.busy": "2022-05-05T17:51:44.317518Z",
     "iopub.status.idle": "2022-05-05T17:51:44.329581Z",
     "shell.execute_reply": "2022-05-05T17:51:44.328786Z"
    },
    "papermill": {
     "duration": 0.027298,
     "end_time": "2022-05-05T17:51:44.331864",
     "exception": false,
     "start_time": "2022-05-05T17:51:44.304566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3557739",
   "metadata": {
    "papermill": {
     "duration": 0.011413,
     "end_time": "2022-05-05T17:51:44.354965",
     "exception": false,
     "start_time": "2022-05-05T17:51:44.343552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model in this particular problem can take quite a few epochs to complete training, so we'll include an early stopping callback for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7c3083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:44.379527Z",
     "iopub.status.busy": "2022-05-05T17:51:44.379235Z",
     "iopub.status.idle": "2022-05-05T17:51:45.866493Z",
     "shell.execute_reply": "2022-05-05T17:51:45.865689Z"
    },
    "papermill": {
     "duration": 1.502202,
     "end_time": "2022-05-05T17:51:45.868789",
     "exception": false,
     "start_time": "2022-05-05T17:51:44.366587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 17:51:44.476694: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=512,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=0, # hide the output because we have so many epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51553df",
   "metadata": {
    "papermill": {
     "duration": 0.012027,
     "end_time": "2022-05-05T17:51:45.893150",
     "exception": false,
     "start_time": "2022-05-05T17:51:45.881123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll take a look at the learning curves as always, and also inspect the best values for the loss and accuracy we got on the validation set. (Remember that early stopping will restore the weights to those that got these values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31915ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T17:51:45.919443Z",
     "iopub.status.busy": "2022-05-05T17:51:45.919169Z",
     "iopub.status.idle": "2022-05-05T17:51:46.344437Z",
     "shell.execute_reply": "2022-05-05T17:51:46.343660Z"
    },
    "papermill": {
     "duration": 0.441151,
     "end_time": "2022-05-05T17:51:46.346481",
     "exception": false,
     "start_time": "2022-05-05T17:51:45.905330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss: 0.6364\n",
      "Best Validation Accuracy: 0.7143\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5\n",
    "history_df.loc[5:, ['loss', 'val_loss']].plot()\n",
    "history_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n",
    "\n",
    "print((\"Best Validation Loss: {:0.4f}\" +\\\n",
    "      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n",
    "      .format(history_df['val_loss'].min(), \n",
    "              history_df['val_binary_accuracy'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b910b",
   "metadata": {
    "papermill": {
     "duration": 0.014202,
     "end_time": "2022-05-05T17:51:46.376744",
     "exception": false,
     "start_time": "2022-05-05T17:51:46.362542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Your Turn #\n",
    "\n",
    "Use a neural network to [**predict cancellations in hotel reservations**](https://www.kaggle.com/kernels/fork/11887335) with the *Hotel Cancellations* dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad17c1f",
   "metadata": {
    "papermill": {
     "duration": 0.015487,
     "end_time": "2022-05-05T17:51:46.407486",
     "exception": false,
     "start_time": "2022-05-05T17:51:46.391999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-deep-learning/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.692016,
   "end_time": "2022-05-05T17:51:52.457795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-05T17:51:32.765779",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
